"""Shared helpers across harness adapters."""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import cast

from meridian.lib.domain import TokenUsage
from meridian.lib.harness.adapter import ArtifactStore, StreamEvent
from meridian.lib.types import ArtifactKey, RunId


def _payload_text(payload: dict[str, object], key: str, *, default: str = "?") -> str:
    value = payload.get(key)
    if value is None:
        return default
    rendered = str(value).strip()
    return rendered or default


def _synthesize_meridian_protocol_text(
    *,
    event_type: str,
    payload: dict[str, object],
) -> str | None:
    if event_type == "run.start":
        run_id = _payload_text(payload, "id")
        model = _payload_text(payload, "model")
        agent = payload.get("agent")
        if agent is None or not str(agent).strip():
            return f"{run_id} {model} started"
        return f"{run_id} {model} ({str(agent).strip()}) started"

    if event_type == "run.done":
        run_id = _payload_text(payload, "id")
        secs = _payload_text(payload, "secs")
        exit_code = _payload_text(payload, "exit")
        rendered = f"{run_id} completed {secs}s exit={exit_code}"
        tokens = payload.get("tok")
        if tokens is not None:
            rendered = f"{rendered} tok={tokens}"
        return rendered

    return None


def parse_json_stream_event(line: str) -> StreamEvent | None:
    stripped = line.strip()
    if not stripped:
        return None
    try:
        payload_obj = json.loads(stripped)
    except json.JSONDecodeError:
        return StreamEvent(
            event_type="line",
            category="progress",
            raw_line=line,
            text=stripped,
        )

    if not isinstance(payload_obj, dict):
        return StreamEvent(
            event_type="line",
            category="progress",
            raw_line=line,
            text=stripped,
        )

    payload = cast("dict[str, object]", payload_obj)
    event_type = str(payload.get("type") or payload.get("t") or payload.get("event") or "line")
    text = payload.get("text") or payload.get("message")
    # Recognize both "run.*" and "meridian.run.*" as meridian protocol events.
    synth_type = event_type
    if synth_type.startswith("meridian."):
        synth_type = synth_type[len("meridian."):]
    category = "sub-run" if synth_type.startswith("run.") else "progress"
    if text is None and "t" in payload and synth_type.startswith("run."):
        text = _synthesize_meridian_protocol_text(event_type=synth_type, payload=payload)
    if text is not None:
        return StreamEvent(
            event_type=event_type,
            category=category,
            raw_line=line,
            text=str(text),
            metadata=payload,
        )
    return StreamEvent(
        event_type=event_type,
        category=category,
        raw_line=line,
        text=None,
        metadata=payload,
    )


def categorize_stream_event(
    event: StreamEvent,
    *,
    exact_map: dict[str, str] | None = None,
) -> StreamEvent:
    normalized = event.event_type.strip().lower()
    category = _category_from_event_type(normalized, exact_map=exact_map)
    return StreamEvent(
        event_type=event.event_type,
        category=category,
        raw_line=event.raw_line,
        text=event.text,
        metadata=event.metadata,
    )


def _category_from_event_type(
    normalized_event_type: str,
    *,
    exact_map: dict[str, str] | None,
) -> str:
    if exact_map is not None and normalized_event_type in exact_map:
        return exact_map[normalized_event_type]

    if normalized_event_type.startswith("run.") or normalized_event_type.startswith(
        "meridian.run."
    ):
        return "sub-run"
    if any(token in normalized_event_type for token in ("error", "fail", "warning", "warn")):
        return "error"
    if any(token in normalized_event_type for token in ("tool", "function_call", "call_tool")):
        return "tool-use"
    if any(token in normalized_event_type for token in ("think", "reasoning", "reason")):
        return "thinking"
    if any(token in normalized_event_type for token in ("assistant", "message", "response")):
        return "assistant"
    if any(
        token in normalized_event_type
        for token in (
            "start",
            "started",
            "finish",
            "finished",
            "complete",
            "completed",
            "done",
            "result",
        )
    ):
        return "lifecycle"
    return "progress"


def _read_json_artifact(
    artifacts: ArtifactStore, run_id: RunId, filename: str
) -> dict[str, object] | None:
    artifact_key = ArtifactKey(f"{run_id}/{filename}")
    if not artifacts.exists(artifact_key):
        return None
    raw = artifacts.get(artifact_key)
    try:
        payload_obj = json.loads(raw.decode("utf-8"))
    except (UnicodeDecodeError, json.JSONDecodeError):
        return None
    if isinstance(payload_obj, dict):
        return cast("dict[str, object]", payload_obj)
    return None


@dataclass(frozen=True, slots=True)
class _UsageCandidate:
    input_tokens: int | None = None
    output_tokens: int | None = None
    total_cost_usd: float | None = None


TOKEN_KEY_PAIRS: tuple[tuple[str, str], ...] = (
    ("input_tokens", "output_tokens"),
    ("input", "output"),
    ("prompt_tokens", "completion_tokens"),
    ("prompt_token_count", "completion_token_count"),
    ("inputTokenCount", "outputTokenCount"),
)
COST_KEYS: tuple[str, ...] = (
    "total_cost_usd",
    "cost_usd",
    "cost",
    "total_cost",
    "totalCostUsd",
)


def _coerce_optional_int(value: object) -> int | None:
    if isinstance(value, bool):
        return int(value)
    if isinstance(value, int):
        return value
    if isinstance(value, float):
        return int(value)
    if isinstance(value, str):
        stripped = value.strip()
        if not stripped:
            return None
        try:
            return int(stripped)
        except ValueError:
            return None
    return None


def _coerce_optional_float(value: object) -> float | None:
    if isinstance(value, bool):
        return float(value)
    if isinstance(value, int | float):
        return float(value)
    if isinstance(value, str):
        stripped = value.strip()
        if not stripped:
            return None
        if stripped.startswith("$"):
            stripped = stripped[1:]
        try:
            return float(stripped)
        except ValueError:
            return None
    return None


def _iter_dicts(value: object) -> list[dict[str, object]]:
    found: list[dict[str, object]] = []
    if isinstance(value, dict):
        payload = cast("dict[str, object]", value)
        found.append(payload)
        for nested in payload.values():
            found.extend(_iter_dicts(nested))
    elif isinstance(value, list):
        for item in cast("list[object]", value):
            found.extend(_iter_dicts(item))
    return found


def _extract_cost(payload: dict[str, object]) -> float | None:
    for key in COST_KEYS:
        value = _coerce_optional_float(payload.get(key))
        if value is not None:
            return value
    return None


def _candidate_from_payload(payload: dict[str, object]) -> _UsageCandidate:
    for input_key, output_key in TOKEN_KEY_PAIRS:
        if input_key not in payload and output_key not in payload:
            continue
        input_tokens = _coerce_optional_int(payload.get(input_key))
        output_tokens = _coerce_optional_int(payload.get(output_key))
        cost = _extract_cost(payload)
        return _UsageCandidate(
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            total_cost_usd=cost,
        )

    return _UsageCandidate(total_cost_usd=_extract_cost(payload))


def _candidate_token_score(candidate: _UsageCandidate) -> int:
    score = 0
    if candidate.input_tokens is not None:
        score += 1
    if candidate.output_tokens is not None:
        score += 1
    return score


def _iter_json_lines_artifact(
    artifacts: ArtifactStore, run_id: RunId, filename: str
) -> list[dict[str, object]]:
    artifact_key = ArtifactKey(f"{run_id}/{filename}")
    if not artifacts.exists(artifact_key):
        return []

    raw = artifacts.get(artifact_key)
    decoded = raw.decode("utf-8", errors="ignore")
    payloads: list[dict[str, object]] = []
    for line in decoded.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        try:
            payload_obj = json.loads(stripped)
        except json.JSONDecodeError:
            continue
        if isinstance(payload_obj, dict):
            payloads.append(cast("dict[str, object]", payload_obj))
    return payloads


def extract_usage_from_artifacts(artifacts: ArtifactStore, run_id: RunId) -> TokenUsage:
    candidates: list[_UsageCandidate] = []

    for filename in ("tokens.json", "usage.json"):
        payload = _read_json_artifact(artifacts, run_id, filename)
        if payload is None:
            continue
        for nested in _iter_dicts(payload):
            candidates.append(_candidate_from_payload(nested))

    for payload in _iter_json_lines_artifact(artifacts, run_id, "output.jsonl"):
        for nested in _iter_dicts(payload):
            candidates.append(_candidate_from_payload(nested))

    if not candidates:
        return TokenUsage()

    best_tokens = max(candidates, key=_candidate_token_score)
    best_cost = next(
        (
            candidate.total_cost_usd
            for candidate in candidates
            if candidate.total_cost_usd is not None
        ),
        None,
    )

    if _candidate_token_score(best_tokens) == 0 and best_cost is None:
        return TokenUsage()

    return TokenUsage(
        input_tokens=best_tokens.input_tokens or 0,
        output_tokens=best_tokens.output_tokens or 0,
        total_cost_usd=best_cost,
    )


def extract_session_id_from_artifacts(artifacts: ArtifactStore, run_id: RunId) -> str | None:
    key = ArtifactKey(f"{run_id}/session_id.txt")
    if not artifacts.exists(key):
        for payload in _iter_json_lines_artifact(artifacts, run_id, "output.jsonl"):
            for nested in _iter_dicts(payload):
                for key_name in ("session_id", "sessionId"):
                    value = nested.get(key_name)
                    if not isinstance(value, str):
                        continue
                    stripped = value.strip()
                    if stripped:
                        return stripped
        return None

    raw = artifacts.get(key)
    session_id = raw.decode("utf-8", errors="ignore").strip()
    return session_id or None
